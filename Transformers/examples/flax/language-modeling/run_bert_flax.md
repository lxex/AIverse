è¿™æ®µä»£ç æ˜¯ **JAX ç‰ˆ BERT æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬**ï¼Œä¸»è¦åŠŸèƒ½æ˜¯ **æµ‹è¯• `FlaxBertModel` çš„æ¨ç†ååé‡**ï¼Œä»£ç é€»è¾‘å¦‚ä¸‹ï¼š
1. **è§£æå‚æ•°**ï¼Œé€‰æ‹© `float32` æˆ– `bfloat16` è¿›è¡Œè®¡ç®—ã€‚
2. **å®šä¹‰æ•°æ®ç”Ÿæˆå‡½æ•°**ï¼Œåˆ›å»ºéšæœºè¾“å…¥ã€‚
3. **åŠ è½½ `FlaxBertModel`**ï¼Œä½¿ç”¨ `BERT base` é¢„è®­ç»ƒæ¨¡å‹ã€‚
4. **JIT ç¼–è¯‘æ¨¡å‹å‰å‘è®¡ç®—**ï¼ŒåŠ é€Ÿæ¨ç†ã€‚
5. **è¿›è¡Œæ¨ç†åŸºå‡†æµ‹è¯•**ï¼Œæµ‹é‡ **ååé‡ï¼ˆexamples/secï¼‰**ã€‚

---

## **1. ä»£ç è§£æ**
### **(1) è§£æå‚æ•°**
```python
parser = ArgumentParser()
parser.add_argument("--precision", type=str, choices=["float32", "bfloat16"], default="float32")
args = parser.parse_args()

dtype = jax.numpy.float32
if args.precision == "bfloat16":
    dtype = jax.numpy.bfloat16
```
- **æ”¯æŒ `float32` å’Œ `bfloat16` è®¡ç®—**
- `bfloat16` åœ¨ **TPU** æˆ– **æŸäº› GPUï¼ˆå¦‚ A100ï¼‰** ä¸Šå¯ä»¥åŠ é€Ÿæ¨ç†

---

### **(2) ç”Ÿæˆè¾“å…¥æ•°æ®**
```python
VOCAB_SIZE = 30522
BS = 32
SEQ_LEN = 128


def get_input_data(batch_size=1, seq_length=384):
    shape = (batch_size, seq_length)
    input_ids = np.random.randint(1, VOCAB_SIZE, size=shape).astype(np.int32)
    token_type_ids = np.ones(shape).astype(np.int32)
    attention_mask = np.ones(shape).astype(np.int32)
    return {"input_ids": input_ids, "token_type_ids": token_type_ids, "attention_mask": attention_mask}


inputs = get_input_data(BS, SEQ_LEN)
```
- `input_ids`ï¼šéšæœºç”Ÿæˆ `[1, VOCAB_SIZE]` ä¹‹é—´çš„ token id
- `token_type_ids`ï¼šè®¾ç½®ä¸º `1`ï¼ˆè¡¨ç¤ºå±äºåŒä¸€ä¸ªå¥å­ï¼‰
- `attention_mask`ï¼šå…¨ `1`ï¼ˆæ—  paddingï¼‰

---

### **(3) åŠ è½½ `FlaxBertModel`**
```python
config = BertConfig.from_pretrained("bert-base-uncased", hidden_act="gelu_new")
model = FlaxBertModel.from_pretrained("bert-base-uncased", config=config, dtype=dtype)
```
- **ä» Hugging Face ä¸‹è½½ `bert-base-uncased` é¢„è®­ç»ƒæ¨¡å‹**
- `hidden_act="gelu_new"` æŒ‡å®š GELU æ¿€æ´»å‡½æ•°
- **ä½¿ç”¨ `float32` æˆ– `bfloat16` è¿›è¡Œè®¡ç®—**

---

### **(4) JIT ç¼–è¯‘å‰å‘è®¡ç®—**
```python
@jax.jit
def func():
    outputs = model(**inputs)
    return outputs
```
- **ä½¿ç”¨ `@jax.jit` ç¼–è¯‘æ¨¡å‹å‰å‘è®¡ç®—**
- JIT å¯ä»¥ **ä¼˜åŒ–è®¡ç®—å›¾ã€åŠ é€Ÿæ¨ç†**

---

### **(5) è¿›è¡ŒåŸºå‡†æµ‹è¯•**
```python
(nwarmup, nbenchmark) = (5, 100)

# warmup
for _ in range(nwarmup):
    func()

# benchmark
start = time.time()
for _ in range(nbenchmark):
    func()
end = time.time()

print(end - start)
print(f"Throughput: {((nbenchmark * BS)/(end-start)):.3f} examples/sec")
```
- **é¢„çƒ­ï¼ˆwarmupï¼‰5 æ¬¡**ï¼Œè®© JIT ç¼–è¯‘å®Œæˆ
- **æ­£å¼æµ‹è¯• 100 æ¬¡**ï¼Œè®¡ç®— **ååé‡ï¼ˆexamples/secï¼‰**

---

## **2. ä»£ç æ‰©å±•**
### **(1) æ”¯æŒ `TPU/GPU` è‡ªåŠ¨åŠ é€Ÿ**
å¯ä»¥ **è‡ªåŠ¨æ£€æµ‹ GPU/TPU è®¾å¤‡** å¹¶è¿›è¡Œä¼˜åŒ–ï¼š
```python
import jax.tools.colab_tpu

if "COLAB_TPU_ADDR" in os.environ:
    jax.tools.colab_tpu.setup_tpu()
    print("Using TPU")
else:
    print("Using GPU or CPU")
```
è¿™æ ·åœ¨ Colab **TPU/GPU è¿è¡Œæ—¶** ä¼šè‡ªåŠ¨ä½¿ç”¨æ›´å¿«çš„è®¾å¤‡ã€‚

---

### **(2) è®¡ç®— `latency`**
å¯ä»¥ **è®¡ç®—æ¯ä¸ª batch å¤„ç†æ—¶é—´**ï¼š
```python
latency = (end - start) / nbenchmark
print(f"Latency per batch: {latency:.6f} sec")
```

---

## **3. ä»£ç æ€»ç»“**
- **åŠ è½½ `FlaxBertModel` å¹¶è¿›è¡Œ `JAX` åŠ é€Ÿ**
- **ä½¿ç”¨ `@jax.jit` ç¼–è¯‘è®¡ç®—å›¾**
- **è¿›è¡Œæ¨ç†ååé‡æµ‹è¯•**
- **æ”¯æŒ `float32` å’Œ `bfloat16`**

é€‚ç”¨äº **BERT æ¨¡å‹æ€§èƒ½è¯„ä¼° & æ¨ç†ä¼˜åŒ–** ğŸš€