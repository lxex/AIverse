## **ä»£ç è§£æä¸æŠ€æœ¯æ‰©å±•**

### **1. ä»£ç æ•´ä½“ä½œç”¨**
è¿™æ®µä»£ç çš„ä½œç”¨æ˜¯ï¼š
- **åˆ›å»º `FlaxVisionEncoderDecoderModel`ï¼ˆè§†è§‰-æ–‡æœ¬æ¨¡å‹ï¼‰**
- **ä»é¢„è®­ç»ƒçš„ç¼–ç å™¨ï¼ˆè§†è§‰æ¨¡å‹ï¼‰å’Œè§£ç å™¨ï¼ˆæ–‡æœ¬æ¨¡å‹ï¼‰åŠ è½½æƒé‡**
- **é€‚é… `Flax` æ¡†æ¶**ï¼ˆJAX ç‰ˆæœ¬çš„ `transformers`ï¼‰
- **è°ƒæ•´ `decoder` ç›¸å…³çš„ç‰¹æ®Š token**
- **ä¿å­˜æœ€ç»ˆçš„æ¨¡å‹ã€å›¾åƒå¤„ç†å™¨ï¼ˆ`image_processor`ï¼‰ã€åˆ†è¯å™¨ï¼ˆ`tokenizer`ï¼‰**

è¿™ç§ **è§†è§‰-æ–‡æœ¬æ¨¡å‹** é€‚ç”¨äº **å›¾åƒå­—å¹•ç”Ÿæˆï¼ˆimage captioningï¼‰ã€å›¾åƒé—®ç­”ï¼ˆVQAï¼‰** ç­‰ä»»åŠ¡ï¼Œå¸¸è§æ¶æ„å¦‚ï¼š
- `ViT + GPT2`
- `CLIP + T5`
- `Swin Transformer + BART`

---

## **2. ä»£ç è§£æï¼ˆè¯¦ç»†è®²è§£ï¼‰**

### **(1) ä»£ç å¤´éƒ¨**
```python
#!/usr/bin/env python
# coding=utf-8
# Copyright 2022 The HuggingFace Team All rights reserved.
```
- `#!/usr/bin/env python`ï¼šæŒ‡ç¤º Python è§£é‡Šå™¨è¿è¡Œæ­¤è„šæœ¬ã€‚
- `# coding=utf-8`ï¼šæ”¯æŒ UTF-8 å­—ç¬¦ç¼–ç ï¼Œé˜²æ­¢ä¸­æ–‡/ç‰¹æ®Šå­—ç¬¦ä¹±ç ã€‚
- **Apache License 2.0**ï¼šå¼€æºè®¸å¯è¯ï¼Œå…è®¸è‡ªç”±ä½¿ç”¨ã€ä¿®æ”¹å’Œåˆ†å‘ä»£ç ã€‚

---

### **(2) å¯¼å…¥åº“**
```python
from dataclasses import dataclass, field
from typing import Optional

from transformers import AutoConfig, AutoImageProcessor, AutoTokenizer, FlaxVisionEncoderDecoderModel, HfArgumentParser
```
- `@dataclass`ï¼šå®šä¹‰å‚æ•°ç±» `ModelArguments`ï¼Œç”¨äºå­˜å‚¨æ¨¡å‹è·¯å¾„ã€é…ç½®å‚æ•°ç­‰ä¿¡æ¯ã€‚
- `Optional`ï¼šå®šä¹‰å¯é€‰å‚æ•°ã€‚
- **Hugging Face `transformers` åº“**ï¼š
  - `AutoConfig`ï¼šåŠ è½½æ¨¡å‹çš„è¶…å‚æ•°ï¼ˆhidden_size, num_layers ç­‰ï¼‰ã€‚
  - `AutoImageProcessor`ï¼šç”¨äºå›¾åƒé¢„å¤„ç†ï¼ˆå½’ä¸€åŒ–ã€resizeï¼‰ã€‚
  - `AutoTokenizer`ï¼šåŠ è½½æ–‡æœ¬æ¨¡å‹çš„åˆ†è¯å™¨ï¼ˆå¦‚ GPT2ï¼‰ã€‚
  - `FlaxVisionEncoderDecoderModel`ï¼šJAX ç‰ˆæœ¬çš„è§†è§‰-æ–‡æœ¬æ¨¡å‹ã€‚
  - `HfArgumentParser`ï¼šç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°ã€‚

---

### **(3) è§£æè¾“å…¥å‚æ•°**
```python
@dataclass
class ModelArguments:
    """
    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.
    """
    output_dir: str = field(metadata={"help": "The output directory where the model will be written."})
    encoder_model_name_or_path: str = field(metadata={"help": "The encoder model checkpoint for weights initialization."})
    decoder_model_name_or_path: str = field(metadata={"help": "The decoder model checkpoint for weights initialization."})
    encoder_config_name: Optional[str] = field(default=None, metadata={"help": "Encoder config name if different."})
    decoder_config_name: Optional[str] = field(default=None, metadata={"help": "Decoder config name if different."})
```
- **è§£ææ¨¡å‹è·¯å¾„å‚æ•°**ï¼š
  - `encoder_model_name_or_path`ï¼šç¼–ç å™¨ï¼ˆè§†è§‰æ¨¡å‹ï¼‰çš„é¢„è®­ç»ƒæƒé‡è·¯å¾„ã€‚
  - `decoder_model_name_or_path`ï¼šè§£ç å™¨ï¼ˆæ–‡æœ¬æ¨¡å‹ï¼‰çš„é¢„è®­ç»ƒæƒé‡è·¯å¾„ã€‚
  - `encoder_config_name` / `decoder_config_name`ï¼ˆå¯é€‰ï¼‰ï¼šå¦‚æœ `config` è·¯å¾„ä¸ `model` ä¸åŒï¼Œå¯ä»¥å•ç‹¬æŒ‡å®šã€‚

---

### **(4) `main()` å…¥å£**
```python
def main():
    parser = HfArgumentParser((ModelArguments,))
    (model_args,) = parser.parse_args_into_dataclasses()
```
- `HfArgumentParser` **è§£æå‘½ä»¤è¡Œå‚æ•°**ï¼Œå¹¶å­˜å‚¨åˆ° `model_args`ã€‚

---

### **(5) åŠ è½½ç¼–ç å™¨ï¼ˆå›¾åƒæ¨¡å‹ï¼‰é…ç½®**
```python
if model_args.encoder_config_name:
    encoder_config = AutoConfig.from_pretrained(model_args.encoder_config_name)
else:
    encoder_config = AutoConfig.from_pretrained(model_args.encoder_model_name_or_path)
```
- å¦‚æœç”¨æˆ· **æ˜¾å¼æŒ‡å®šäº† `encoder_config_name`**ï¼Œåˆ™åŠ è½½è¯¥é…ç½®ã€‚
- å¦åˆ™ï¼Œä» **é¢„è®­ç»ƒæ¨¡å‹** (`encoder_model_name_or_path`) åŠ è½½é»˜è®¤é…ç½®ã€‚

---

### **(6) åŠ è½½è§£ç å™¨ï¼ˆæ–‡æœ¬æ¨¡å‹ï¼‰é…ç½®**
```python
if model_args.decoder_config_name:
    decoder_config = AutoConfig.from_pretrained(model_args.decoder_config_name)
else:
    decoder_config = AutoConfig.from_pretrained(model_args.decoder_model_name_or_path)

decoder_config.is_decoder = True
decoder_config.add_cross_attention = True
```
- `decoder_config.is_decoder = True`ï¼šæ˜ç¡®æ ‡è®° **è§£ç å™¨æ¨¡å¼**ï¼ˆé¿å… Transformer è¯¯åˆ¤ï¼‰ã€‚
- `decoder_config.add_cross_attention = True`ï¼š**å¼€å¯è·¨æ³¨æ„åŠ›æœºåˆ¶**ï¼Œä½¿ `decoder` å¯ä»¥æ¥æ”¶ `encoder` è¾“å‡ºã€‚

---

### **(7) åˆ›å»º `FlaxVisionEncoderDecoderModel`**
```python
model = FlaxVisionEncoderDecoderModel.from_encoder_decoder_pretrained(
    encoder_pretrained_model_name_or_path=model_args.encoder_model_name_or_path,
    decoder_pretrained_model_name_or_path=model_args.decoder_model_name_or_path,
    encoder_config=encoder_config,
    decoder_config=decoder_config,
)
```
- **åŠ è½½ `FlaxVisionEncoderDecoderModel`**
  - **Encoderï¼ˆè§†è§‰æ¨¡å‹ï¼‰** â†’ `ViTã€CLIPã€Swin`
  - **Decoderï¼ˆæ–‡æœ¬æ¨¡å‹ï¼‰** â†’ `GPT2ã€T5ã€BART`

---

### **(8) å¤„ç† `decoder` çš„ç‰¹æ®Š token**
```python
decoder_start_token_id = decoder_config.decoder_start_token_id
pad_token_id = decoder_config.pad_token_id
if decoder_start_token_id is None:
    decoder_start_token_id = decoder_config.bos_token_id
if pad_token_id is None:
    pad_token_id = decoder_config.eos_token_id

model.config.eos_token_id = decoder_config.eos_token_id
model.config.decoder_start_token_id = decoder_start_token_id
model.config.pad_token_id = pad_token_id
```
- **`decoder_start_token_id`**ï¼šè§£ç å™¨çš„èµ·å§‹ tokenã€‚
- **`pad_token_id`**ï¼šå¡«å…… tokenï¼Œç¡®ä¿ batch å¤„ç†æ—¶å¯¹é½ã€‚
- **GPT2 æ²¡æœ‰ `decoder_start_token_id`ï¼Œå› æ­¤é»˜è®¤ä½¿ç”¨ `bos_token_id`**ã€‚

---

### **(9) åŠ è½½å›¾åƒå¤„ç†å™¨**
```python
image_processor = AutoImageProcessor.from_pretrained(model_args.encoder_model_name_or_path)
```
- **å›¾åƒé¢„å¤„ç†å™¨**ï¼ˆå½’ä¸€åŒ–ã€å°ºå¯¸è°ƒæ•´ï¼‰ã€‚
- é€‚ç”¨äº `ViTã€CLIPã€Swin Transformer`ã€‚

---

### **(10) åŠ è½½åˆ†è¯å™¨**
```python
tokenizer = AutoTokenizer.from_pretrained(model_args.decoder_model_name_or_path)
tokenizer.pad_token = tokenizer.convert_ids_to_tokens(model.config.pad_token_id)
```
- **æ–‡æœ¬æ¨¡å‹çš„åˆ†è¯å™¨ï¼ˆå¦‚ GPT2ï¼‰**ã€‚
- **è®¾ç½® `pad_token`**ï¼Œç¡®ä¿ `decoder` å¯ä»¥æ­£ç¡®å¡«å……åºåˆ—ã€‚

---

### **(11) ä¿å­˜æ¨¡å‹**
```python
model.save_pretrained(model_args.output_dir)
image_processor.save_pretrained(model_args.output_dir)
tokenizer.save_pretrained(model_args.output_dir)
```
- **ä¿å­˜æ¨¡å‹ã€é¢„å¤„ç†å™¨ã€åˆ†è¯å™¨**ï¼Œä¾¿äºåç»­å¾®è°ƒå’Œæ¨ç†ã€‚

---

## **3. æŠ€æœ¯æ‰©å±•**
### **(1) é€‚é… `PyTorch` ç‰ˆæœ¬**
```python
from transformers import VisionEncoderDecoderModel
model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained("facebook/detr-resnet-50", "gpt2")
```
- **é€‚ç”¨äº `torch`ï¼Œè€Œä¸æ˜¯ `Flax/JAX`**ã€‚

---

### **(2) æ›´æ¢ `Encoder` æˆ– `Decoder`**
```python
encoder_model = "openai/clip-vit-large-patch14"
decoder_model = "facebook/bart-large-cnn"
```
- `CLIP` ä½œä¸º `encoder`ï¼Œ`BART` ä½œä¸º `decoder`ã€‚

---

### **(3) ç”Ÿæˆæ–‡æœ¬ï¼ˆæ¨ç†ï¼‰**
```python
inputs = image_processor(images=image, return_tensors="jax")
generated = model.generate(**inputs)
print(tokenizer.decode(generated[0], skip_special_tokens=True))
```
- ç›´æ¥ **è¾“å…¥å›¾åƒï¼Œç”Ÿæˆæ–‡æœ¬æè¿°**ã€‚

---

## **æ€»ç»“**
- **åŸºäº Flax/JAX çš„ `VisionEncoderDecoderModel` ä»£ç **
- **æ”¯æŒ `ViT + GPT2` æˆ– `CLIP + T5`**
- **é€‚ç”¨äºå›¾åƒå­—å¹•ç”Ÿæˆï¼ˆImage Captioningï¼‰**
- **å¤„ç† `decoder` ç‰¹æ®Š token**
- **å¯ä»¥æ‰©å±•åˆ° `PyTorch`ï¼Œæ”¯æŒ `AllReduce` è®­ç»ƒ**

ğŸš€ **è¿™å¥—æ¶æ„å¯ä»¥ç”¨äºå¤šæ¨¡æ€ä»»åŠ¡ï¼Œå¦‚ DALLÂ·Eã€BLIP ç­‰ï¼**