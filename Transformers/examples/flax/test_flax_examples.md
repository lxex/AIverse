è¿™æ®µä»£ç æ˜¯ **Flaxï¼ˆJAXï¼‰** ç‰ˆæœ¬çš„ **Transformers æµ‹è¯•è„šæœ¬**ï¼Œç”¨äºæµ‹è¯• **å¤šä¸ª NLP å’Œè¯­éŸ³ä»»åŠ¡çš„ Fine-tune è®­ç»ƒ**ï¼ŒåŒ…æ‹¬ï¼š

âœ… **æ–‡æœ¬åˆ†ç±»** (`run_flax_glue.py`)  
âœ… **Causal Language Model (CLM)** (`run_clm_flax.py`)  
âœ… **æ‘˜è¦ç”Ÿæˆ (Summarization)** (`run_summarization_flax.py`)  
âœ… **æ©ç è¯­è¨€æ¨¡å‹ (MLM)** (`run_mlm_flax.py`)  
âœ… **T5 é¢„è®­ç»ƒ (T5-MLM)** (`run_t5_mlm_flax.py`)  
âœ… **å‘½åå®ä½“è¯†åˆ« (NER)** (`run_flax_ner.py`)  
âœ… **é—®ç­” (QA)** (`run_qa.py`)  
âœ… **è¯­éŸ³è¯†åˆ« (Speech-to-Text)** (`run_flax_speech_recognition_seq2seq.py`)  

---

## **1. ä»£ç æ‰§è¡Œæµç¨‹**
### **1ï¸âƒ£ å¯¼å…¥æ¨¡å—**
```python
import argparse
import json
import logging
import os
import sys
from unittest.mock import patch
```
- ä½¿ç”¨ `unittest.mock.patch` **æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°**ï¼ˆé¿å…æ‰‹åŠ¨ä¼ é€’ï¼‰ã€‚
- è®¾å®š **æ—¥å¿—** çº§åˆ« `logging.DEBUG`ï¼Œæ–¹ä¾¿è°ƒè¯•ã€‚

---

### **2ï¸âƒ£ æ·»åŠ ä¸åŒä»»åŠ¡çš„è„šæœ¬è·¯å¾„**
```python
SRC_DIRS = [
    os.path.join(os.path.dirname(__file__), dirname)
    for dirname in [
        "text-classification",
        "language-modeling",
        "summarization",
        "token-classification",
        "question-answering",
        "speech-recognition",
    ]
]
sys.path.extend(SRC_DIRS)
```
- è¿™äº›è·¯å¾„æŒ‡å‘ **ä¸åŒ NLP ä»»åŠ¡çš„è®­ç»ƒä»£ç **ï¼Œå¦‚ `run_glue.py`ï¼Œ`run_mlm.py` ç­‰ã€‚
- è¿™æ ·å¯ä»¥ **åŠ¨æ€å¯¼å…¥** è¿™äº› Python ä»£ç æ–‡ä»¶ã€‚

```python
import run_clm_flax
import run_flax_glue
import run_flax_ner
import run_flax_speech_recognition_seq2seq
import run_mlm_flax
import run_qa
import run_summarization_flax
import run_t5_mlm_flax
```
- è¿™é‡Œå®é™… **å¯¼å…¥äº†å¤šä¸ª JAX/Flax è®­ç»ƒè„šæœ¬**ï¼Œä»¥ä¾¿åç»­è°ƒç”¨ã€‚

---

### **3ï¸âƒ£ è¿è¡Œæµ‹è¯•ä»»åŠ¡**
```python
class ExamplesTests(TestCasePlus):
```
è¯¥ç±»ç»§æ‰¿äº† `TestCasePlus`ï¼Œæ˜¯ Transformers **ä¸“ç”¨æµ‹è¯•ç±»**ï¼ŒåŒ…å«å¤šä¸ªæµ‹è¯•ä»»åŠ¡ã€‚

#### **ğŸ“Œ ä»»åŠ¡ 1ï¼šæ–‡æœ¬åˆ†ç±»ï¼ˆGLUEï¼‰**
```python
def test_run_glue(self):
    tmp_dir = self.get_auto_remove_tmp_dir()
    testargs = f"""
        run_glue.py
        --model_name_or_path distilbert/distilbert-base-uncased
        --output_dir {tmp_dir}
        --train_file ./tests/fixtures/tests_samples/MRPC/train.csv
        --validation_file ./tests/fixtures/tests_samples/MRPC/dev.csv
        --per_device_train_batch_size=2
        --per_device_eval_batch_size=1
        --learning_rate=1e-4
        --eval_steps=2
        --warmup_steps=2
        --seed=42
        --max_seq_length=128
        """.split()
    
    with patch.object(sys, "argv", testargs):
        run_flax_glue.main()
        result = get_results(tmp_dir)
        self.assertGreaterEqual(result["eval_accuracy"], 0.75)
```
- ä½¿ç”¨ `patch.object(sys, "argv", testargs)` **æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°**ï¼Œé¿å…æ‰‹åŠ¨è¾“å…¥ã€‚
- è°ƒç”¨ `run_flax_glue.main()` è¿è¡Œæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€‚
- è®­ç»ƒå®Œæˆåï¼Œè°ƒç”¨ `get_results(tmp_dir)` **æ£€æŸ¥æµ‹è¯•å‡†ç¡®ç‡æ˜¯å¦ >= 0.75**ã€‚

---

#### **ğŸ“Œ ä»»åŠ¡ 2ï¼šCausal Language Model (CLM) è®­ç»ƒ**
```python
@slow
def test_run_clm(self):
    tmp_dir = self.get_auto_remove_tmp_dir()
    testargs = f"""
        run_clm_flax.py
        --model_name_or_path distilbert/distilgpt2
        --train_file ./tests/fixtures/sample_text.txt
        --validation_file ./tests/fixtures/sample_text.txt
        --do_train
        --do_eval
        --block_size 128
        --per_device_train_batch_size 4
        --per_device_eval_batch_size 4
        --num_train_epochs 2
        --logging_steps 2 --eval_steps 2
        --output_dir {tmp_dir}
        --overwrite_output_dir
        """.split()

    with patch.object(sys, "argv", testargs):
        run_clm_flax.main()
        result = get_results(tmp_dir)
        self.assertLess(result["eval_perplexity"], 100)
```
- è¿™ä¸ªæµ‹è¯•ä½¿ç”¨ **DistilGPT2** è®­ç»ƒ **Causal LMï¼ˆGPT è¯­è¨€æ¨¡å‹ï¼‰**ã€‚
- è®­ç»ƒæ•°æ®å’ŒéªŒè¯æ•°æ® **éƒ½æ˜¯ `sample_text.txt`**ã€‚
- è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥ `eval_perplexity < 100` **ç¡®ä¿å›°æƒ‘åº¦ä½**ã€‚

---

#### **ğŸ“Œ ä»»åŠ¡ 3ï¼šæ‘˜è¦ç”Ÿæˆ**
```python
@slow
def test_run_summarization(self):
    tmp_dir = self.get_auto_remove_tmp_dir()
    testargs = f"""
        run_summarization.py
        --model_name_or_path google-t5/t5-small
        --train_file tests/fixtures/tests_samples/xsum/sample.json
        --validation_file tests/fixtures/tests_samples/xsum/sample.json
        --test_file tests/fixtures/tests_samples/xsum/sample.json
        --output_dir {tmp_dir}
        --overwrite_output_dir
        --num_train_epochs=3
        --warmup_steps=8
        --do_train
        --do_eval
        --do_predict
        --learning_rate=2e-4
        --per_device_train_batch_size=2
        --per_device_eval_batch_size=1
        --predict_with_generate
    """.split()

    with patch.object(sys, "argv", testargs):
        run_summarization_flax.main()
        result = get_results(tmp_dir, split="test")
        self.assertGreaterEqual(result["test_rouge1"], 10)
        self.assertGreaterEqual(result["test_rouge2"], 2)
        self.assertGreaterEqual(result["test_rougeL"], 7)
        self.assertGreaterEqual(result["test_rougeLsum"], 7)
```
- ä½¿ç”¨ `T5-Small` **åœ¨ XSUM æ•°æ®é›†ä¸Šå¾®è°ƒæ‘˜è¦ç”Ÿæˆä»»åŠ¡**ã€‚
- `--predict_with_generate` è®©æ¨¡å‹ç”Ÿæˆæ‘˜è¦ã€‚
- è®­ç»ƒåï¼Œæ£€æŸ¥ **ROUGE è¯„åˆ†**ï¼š
  - `test_rouge1 â‰¥ 10`
  - `test_rouge2 â‰¥ 2`
  - `test_rougeL â‰¥ 7`
  - `test_rougeLsum â‰¥ 7`

---

#### **ğŸ“Œ ä»»åŠ¡ 4ï¼šMLM é¢„è®­ç»ƒ**
```python
@slow
def test_run_mlm(self):
    tmp_dir = self.get_auto_remove_tmp_dir()
    testargs = f"""
        run_mlm.py
        --model_name_or_path distilbert/distilroberta-base
        --train_file ./tests/fixtures/sample_text.txt
        --validation_file ./tests/fixtures/sample_text.txt
        --output_dir {tmp_dir}
        --overwrite_output_dir
        --max_seq_length 128
        --per_device_train_batch_size 4
        --per_device_eval_batch_size 4
        --logging_steps 2 --eval_steps 2
        --do_train
        --do_eval
        --num_train_epochs=1
    """.split()

    with patch.object(sys, "argv", testargs):
        run_mlm_flax.main()
        result = get_results(tmp_dir)
        self.assertLess(result["eval_perplexity"], 42)
```
- è®­ç»ƒ `DistilRoBERTa` è¿›è¡Œ **æ©ç è¯­è¨€æ¨¡å‹ (MLM) é¢„è®­ç»ƒ**ã€‚
- è®­ç»ƒåï¼Œæ£€æŸ¥ **è¯„ä¼°å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ < 42**ã€‚

---

## **2. æ€»ç»“**
âœ… **ä»£ç æ˜¯ Transformers Flaxï¼ˆJAXï¼‰ è®­ç»ƒè„šæœ¬çš„å•å…ƒæµ‹è¯•**  
âœ… **æµ‹è¯• NLPã€æ‘˜è¦ã€NERã€è¯­éŸ³è¯†åˆ«ç­‰å¤šä¸ªä»»åŠ¡**  
âœ… **ä½¿ç”¨ `patch` æ¨¡æ‹Ÿ CLI å‚æ•°ï¼Œè‡ªåŠ¨è¿è¡Œè®­ç»ƒ & è¯„ä¼°**  
âœ… **è®­ç»ƒåè‡ªåŠ¨æ£€æŸ¥æŒ‡æ ‡ï¼Œå¦‚ `Accuracy`ã€`Perplexity`ã€`ROUGE`**  
âœ… **å¯ä»¥ç”¨äº `pytest` è¿›è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•**

**å¦‚æœä½ æƒ³è¿è¡Œ JAX ç‰ˆæœ¬çš„ NLP ä»»åŠ¡ï¼Œæˆ–è€…ä¿®æ”¹æŸä¸ªæµ‹è¯•ä»»åŠ¡ï¼Œå‘Šè¯‰æˆ‘ï¼** ğŸš€