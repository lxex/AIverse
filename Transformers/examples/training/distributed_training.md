## **ä»£ç è§£æä¸æŠ€æœ¯æ‰©å±•**

### **1. ä»£ç ä½œç”¨**
è¿™æ®µä»£ç ä¸»è¦ç”¨äº **åˆ†å¸ƒå¼è®­ç»ƒ**ï¼Œé‡‡ç”¨ **PyTorch Distributedï¼ˆ`torch.distributed`ï¼‰** è¿›è¡Œå¤š GPUã€å¤šèŠ‚ç‚¹çš„é€šä¿¡ã€‚å®ƒå®ç°äº†ä¸€ä¸ª **ç®€å•çš„ç‚¹å¯¹å¤šç‚¹ï¼ˆone-to-manyï¼‰é€šä¿¡æ¨¡å¼**ï¼š
- **Rank 0 è¿›ç¨‹ï¼ˆä¸»è¿›ç¨‹ï¼‰**ï¼šå‘å…¶ä»–æ‰€æœ‰ Rank å‘é€ä¸€ä¸ªå¼ é‡ `tensor`ã€‚
- **å…¶ä»– Rank è¿›ç¨‹ï¼ˆWorker è¿›ç¨‹ï¼‰**ï¼šä» Rank 0 æ¥æ”¶ `tensor`ã€‚

---

## **2. ä»£ç è§£æï¼ˆè¯¦ç»†è§£è¯»ï¼‰**

### **(1) è§£æ PyTorch åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡**
```python
import argparse
import os

import torch
import torch.distributed as dist
```
- `torch.distributed` æ˜¯ PyTorch çš„åˆ†å¸ƒå¼é€šä¿¡åº“ï¼Œæ”¯æŒå¤š GPUã€å¤šèŠ‚ç‚¹é€šä¿¡ã€‚

```python
LOCAL_RANK = int(os.environ["LOCAL_RANK"])
WORLD_SIZE = int(os.environ["WORLD_SIZE"])
WORLD_RANK = int(os.environ["RANK"])

LOCAL_RANK = int(os.environ["OMPI_COMM_WORLD_LOCAL_RANK"])
WORLD_SIZE = int(os.environ["OMPI_COMM_WORLD_SIZE"])
WORLD_RANK = int(os.environ["OMPI_COMM_WORLD_RANK"])
```
- **ä»ç¯å¢ƒå˜é‡ä¸­è·å–åˆ†å¸ƒå¼è®­ç»ƒä¿¡æ¯**ï¼š
  - `LOCAL_RANK`ï¼šå½“å‰è¿›ç¨‹åœ¨æœ¬åœ°æœºå™¨ä¸Šçš„ GPU IDã€‚
  - `WORLD_SIZE`ï¼šæ€»è¿›ç¨‹æ•°ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„æ€» GPU æ•°ï¼‰ã€‚
  - `WORLD_RANK`ï¼šå½“å‰è¿›ç¨‹çš„å…¨å±€ Rankï¼ˆåœ¨æ•´ä¸ªé›†ç¾¤ä¸­çš„å”¯ä¸€ IDï¼‰ã€‚
- è¿™é‡Œ **é‡å¤èµ‹å€¼** å¯èƒ½ä¼šå¯¼è‡´é—®é¢˜ï¼Œä¸€èˆ¬åªå– **ä¸€ç§æ–¹å¼**ï¼š
  ```python
  LOCAL_RANK = int(os.getenv("LOCAL_RANK", 0))
  WORLD_SIZE = int(os.getenv("WORLD_SIZE", 1))
  WORLD_RANK = int(os.getenv("RANK", 0))
  ```

---

### **(2) å®šä¹‰åˆ†å¸ƒå¼é€šä¿¡æµç¨‹**
```python
def run(backend):
    tensor = torch.zeros(1)
    # éœ€è¦å°† tensor æ”¾åˆ° GPU ä¸Š
    if backend == "nccl":
        device = torch.device("cuda:{}".format(LOCAL_RANK))
        tensor = tensor.to(device)
```
- `tensor = torch.zeros(1)`ï¼šåˆ›å»ºä¸€ä¸ª**åˆå§‹ä¸ºé›¶çš„å¼ é‡**ï¼Œç”¨äº Rank 0 å‘é€æ•°æ®ç»™å…¶ä»–è¿›ç¨‹ã€‚
- `backend == "nccl"` æ—¶ï¼Œéœ€è¦å°† `tensor` æ”¾åˆ° **GPU ä¸Š**ï¼š
  - `"nccl"` åªèƒ½ç”¨äº **NVIDIA GPU**ï¼Œå¹¶ä¸”æ•°æ®å¿…é¡»æ”¾åœ¨ CUDA è®¾å¤‡ä¸Šã€‚
  - `"gloo"` å¯ä»¥ç”¨äº **CPU å’Œ GPU**ï¼Œä½†é€šä¿¡é€Ÿåº¦è¾ƒæ…¢ã€‚

---

### **(3) Rank 0 å‘é€æ•°æ®ï¼Œå…¶ä»– Rank æ¥æ”¶æ•°æ®**
```python
if WORLD_RANK == 0:
    for rank_recv in range(1, WORLD_SIZE):
        dist.send(tensor=tensor, dst=rank_recv)
        print("worker_{} sent data to Rank {}\n".format(0, rank_recv))
else:
    dist.recv(tensor=tensor, src=0)
    print("worker_{} has received data from rank {}\n".format(WORLD_RANK, 0))
```
- **Rank 0** éå†æ‰€æœ‰ `WORLD_SIZE` è¿›ç¨‹ï¼Œå¹¶**å‘æ¯ä¸ªè¿›ç¨‹å‘é€æ•°æ®**ã€‚
- **å…¶ä»– Rank è¿›ç¨‹** ä» `Rank 0` **æ¥æ”¶æ•°æ®**ã€‚

âš  **æ³¨æ„**ï¼š
1. `dist.send()` å’Œ `dist.recv()` æ˜¯ **é˜»å¡æ“ä½œ**ï¼Œéœ€è¦ç¡®ä¿åŒ¹é…ï¼Œå¦åˆ™ä¼šæ­»é”ã€‚
2. `dist.broadcast()` å¯ä»¥æ›¿ä»£ `send-receive` æ–¹å¼ï¼Œæ•ˆç‡æ›´é«˜ï¼š
   ```python
   dist.broadcast(tensor, src=0)
   ```

---

### **(4) åˆå§‹åŒ–è¿›ç¨‹ç»„**
```python
def init_processes(backend):
    dist.init_process_group(backend, rank=WORLD_RANK, world_size=WORLD_SIZE)
    run(backend)
```
- `dist.init_process_group(backend, rank, world_size)` **åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹**ï¼š
  - `backend`ï¼šé€šä¿¡åç«¯ï¼Œæ”¯æŒ `"nccl"`ï¼ˆGPUï¼‰ï¼Œ`"gloo"`ï¼ˆCPU & GPUï¼‰ã€‚
  - `rank`ï¼šå½“å‰è¿›ç¨‹çš„å”¯ä¸€ IDã€‚
  - `world_size`ï¼šè¿›ç¨‹æ€»æ•°ã€‚

---

### **(5) è§£æå‘½ä»¤è¡Œå‚æ•°**
```python
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--local_rank", type=int, help="Local rank. Necessary for using the torch.distributed.launch utility."
    )
    parser.add_argument("--backend", type=str, default="nccl", choices=["nccl", "gloo"])
    args = parser.parse_args()

    init_processes(backend=args.backend)
```
- **è§£æ `--backend` é€‰é¡¹**ï¼Œé»˜è®¤ä½¿ç”¨ `"nccl"`ã€‚
- **å¯åŠ¨åˆ†å¸ƒå¼è¿›ç¨‹**ã€‚

---

## **3. åˆ†å¸ƒå¼è®­ç»ƒçš„è¿è¡Œæ–¹å¼**
### **(1) `torch.distributed.launch` å¯åŠ¨**
```bash
python -m torch.distributed.launch \
    --nproc_per_node=2 --nnodes=2 --node_rank=0 \
    test_compile.py
```
- `--nproc_per_node=2`ï¼šæ¯ä¸ªèŠ‚ç‚¹ 2 ä¸ªè¿›ç¨‹ï¼ˆ2 å¼  GPUï¼‰ã€‚
- `--nnodes=2`ï¼šæ€»å…± 2 ä¸ªèŠ‚ç‚¹ï¼ˆæœºå™¨ï¼‰ã€‚
- `--node_rank=0`ï¼šå½“å‰æœºå™¨ Rank=0ã€‚

---

### **(2) `mpirun` å¯åŠ¨ï¼ˆMPIï¼‰**
```bash
mpirun -np 4 \
-H 104.171.200.62:2,104.171.200.182:2 \
-x MASTER_ADDR=104.171.200.62 \
-x MASTER_PORT=1234 \
-x PATH \
-bind-to none -map-by slot \
-mca pml ob1 -mca btl ^openib \
python3 main.py
```
- `-np 4`ï¼šæ€»å…± 4 ä¸ªè¿›ç¨‹ã€‚
- `-H 104.171.200.62:2,104.171.200.182:2`ï¼šä¸¤ä¸ªæœºå™¨ï¼Œæ¯å° 2 ä¸ª GPUã€‚
- `-x MASTER_ADDR=104.171.200.62`ï¼šæŒ‡å®šä¸»èŠ‚ç‚¹çš„ IPã€‚

---

### **(3) `hostfile` æ–¹å¼**
#### **åˆ›å»º `hostfile`**
```bash
ip-26-0-162-46 slots=8
ip-26-0-162-239 slots=8
```
#### **ä½¿ç”¨ `mpirun` å¯åŠ¨**
```bash
mpirun --hostfile hostfile -np 16 \
    --bind-to none --map-by slot \
    -x MASTER_ADDR=<master-node-ip> \
    -x MASTER_PORT=29500 \
    -x NCCL_DEBUG=INFO \
    -x NCCL_SOCKET_IFNAME=^lo,docker0 \
    -x CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \
    python your_script.py --backend nccl
```
- `slots=8`ï¼šæ¯ä¸ªèŠ‚ç‚¹ 8 å¼  GPUã€‚
- `NCCL_DEBUG=INFO`ï¼šè°ƒè¯•ä¿¡æ¯ã€‚

---

## **4. æŠ€æœ¯æ‰©å±•**
### **(1) æ›¿æ¢ `send/recv` ä¸º `broadcast`ï¼ˆä¼˜åŒ–é€šä¿¡ï¼‰**
```python
dist.broadcast(tensor, src=0)
```
- **å‡å°‘é˜»å¡ï¼Œæé«˜æ•ˆç‡**ã€‚

---

### **(2) æ‰©å±•åˆ° `AllReduce`ï¼ˆæ›´é«˜æ•ˆçš„æ•°æ®åŒæ­¥ï¼‰**
```python
dist.all_reduce(tensor, op=dist.ReduceOp.SUM)
```
- `all_reduce` **è‡ªåŠ¨åŒæ­¥æ‰€æœ‰è¿›ç¨‹çš„æ•°æ®**ï¼ˆé€‚ç”¨äºæ¢¯åº¦åŒæ­¥ï¼‰ã€‚

---

### **(3) ä½¿ç”¨ `torchrun`ï¼ˆPyTorch 2.0 æ¨èï¼‰**
```bash
torchrun --nproc_per_node=2 --nnodes=2 --node_rank=0 \
    --master_addr=104.171.200.62 --master_port=1234 \
    main.py --backend=nccl
```
- **æ›¿ä»£ `torch.distributed.launch`**ï¼Œæ›´åŠ é«˜æ•ˆå’Œç®€æ´ã€‚

---

## **æ€»ç»“**
- **ä»£ç å®ç°äº†åŸºæœ¬çš„ç‚¹å¯¹å¤šç‚¹é€šä¿¡**ï¼Œç”¨äº **åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒåˆå§‹åŒ–**ã€‚
- **æ”¯æŒ `NCCL`ï¼ˆGPUï¼‰å’Œ `GLOO`ï¼ˆCPUï¼‰åç«¯**ã€‚
- **å¯æ‰©å±•ä¸º `AllReduce`ã€`broadcast` è¿›è¡Œæ¢¯åº¦åŒæ­¥**ã€‚
- **æ¨èä½¿ç”¨ `torchrun` è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ**ã€‚

è¿™æ®µä»£ç å¯ä»¥ç”¨äº **å¤š GPUã€å¤šèŠ‚ç‚¹** è®­ç»ƒ **Transformerã€ResNet** ç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹ ğŸš€ï¼