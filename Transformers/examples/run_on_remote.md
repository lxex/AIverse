è¿™æ®µä»£ç æ˜¯ä¸€ä¸ª **Hugging Face è®­ç»ƒè„šæœ¬**ï¼Œç”¨äºåœ¨æœ¬åœ°æˆ–äº‘ç«¯ **è¿œç¨‹ GPU æœåŠ¡å™¨ï¼ˆRunhouse Clusterï¼‰** ä¸Šè¿è¡Œ PyTorch è®­ç»ƒä»»åŠ¡ã€‚å®ƒç»“åˆäº† **Runhouseï¼ˆRHï¼‰** è¿›è¡Œ **è¿œç¨‹ä»»åŠ¡è°ƒåº¦ã€ç¯å¢ƒé…ç½®ã€åŒ…ç®¡ç†å’Œè®­ç»ƒè„šæœ¬æ‰§è¡Œ**ã€‚

## **ä»£ç è§£æ**
---
### **1. ä¾èµ–åº“**
```python
import argparse
import shlex

import runhouse as rh
```
- `argparse`ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°ã€‚
- `shlex`ï¼šç”¨äºå®‰å…¨å¤„ç†å‘½ä»¤è¡Œå‚æ•°ï¼ˆé˜²æ­¢ç©ºæ ¼æˆ–ç‰¹æ®Šå­—ç¬¦é—®é¢˜ï¼‰ã€‚
- `runhouse`ï¼ˆ`rh`ï¼‰ï¼šç”¨äº **åˆ†å¸ƒå¼è®¡ç®—** å’Œ **äº‘ç«¯ç¡¬ä»¶ç®¡ç†**ã€‚

---

### **2. è§£æå‘½ä»¤è¡Œå‚æ•°**
```python
parser = argparse.ArgumentParser()
parser.add_argument("--user", type=str, default="ubuntu")
parser.add_argument("--host", type=str, default="localhost")
parser.add_argument("--key_path", type=str, default=None)
parser.add_argument("--instance", type=str, default="V100:1")
parser.add_argument("--provider", type=str, default="cheapest")
parser.add_argument("--use_spot", type=bool, default=False)
parser.add_argument("--example", type=str, default="pytorch/text-generation/run_generation.py")
args, unknown = parser.parse_known_args()
```
- `--user`ï¼šSSH ç”¨æˆ·åï¼Œé»˜è®¤ `ubuntu`ã€‚
- `--host`ï¼šè¿œç¨‹ä¸»æœº IPï¼Œé»˜è®¤ `localhost`ï¼ˆå³æœ¬æœºï¼‰ã€‚
- `--key_path`ï¼šSSH ç§é’¥è·¯å¾„ï¼Œç”¨äºè¿œç¨‹è¿æ¥ã€‚
- `--instance`ï¼šäº‘ç«¯å®ä¾‹ç±»å‹ï¼Œé»˜è®¤ **V100 GPU**ã€‚
- `--provider`ï¼šäº‘æœåŠ¡æä¾›å•†ï¼Œé»˜è®¤ `cheapest`ï¼ˆRunhouse è‡ªåŠ¨é€‰æ‹©æœ€ä¾¿å®œçš„ï¼‰ã€‚
- `--use_spot`ï¼šæ˜¯å¦ä½¿ç”¨ Spot ä¾¿å®œå®ä¾‹ï¼Œé»˜è®¤ `False`ã€‚
- `--example`ï¼šè¦è¿è¡Œçš„ Hugging Face è®­ç»ƒè„šæœ¬è·¯å¾„ï¼Œé»˜è®¤ `pytorch/text-generation/run_generation.py`ã€‚
- `unknown`ï¼šå­˜å‚¨é¢å¤–çš„å‘½ä»¤è¡Œå‚æ•°ï¼ˆå¦‚ `--batch_size 32`ï¼‰ã€‚

---

### **3. åˆ¤æ–­æ˜¯æœ¬åœ°è¿è¡Œè¿˜æ˜¯è¿œç¨‹æœåŠ¡å™¨**
```python
if args.host != "localhost":
    if args.instance != "V100:1" or args.provider != "cheapest":
        raise ValueError("Cannot specify both BYO and on-demand cluster args")
    cluster = rh.cluster(
        name="rh-cluster", ips=[args.host], ssh_creds={"ssh_user": args.user, "ssh_private_key": args.key_path}
    )
else:
    cluster = rh.cluster(
        name="rh-cluster", instance_type=args.instance, provider=args.provider, use_spot=args.use_spot
    )
```
- **æœ¬åœ°è¿è¡Œï¼ˆ`args.host == "localhost"`ï¼‰**
  - é€šè¿‡ Runhouse åˆ›å»ºä¸€ä¸ª **æŒ‰éœ€äº‘ GPU å®ä¾‹**ï¼ˆé»˜è®¤ `V100`ï¼‰ã€‚
  - Runhouse è‡ªåŠ¨é€‰æ‹©æœ€ä¾¿å®œçš„äº‘æœåŠ¡å•† `provider="cheapest"`ã€‚

- **è¿œç¨‹æœåŠ¡å™¨ï¼ˆ`args.host != "localhost"`ï¼‰**
  - ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ `host` è¿œç¨‹æœåŠ¡å™¨ï¼Œ**SSH è¿æ¥**ã€‚
  - éœ€è¦ `user` å’Œ `key_path` è¿›è¡Œèº«ä»½éªŒè¯ã€‚

- **é”™è¯¯æ£€æŸ¥**
  - ä¸èƒ½ **åŒæ—¶æŒ‡å®š** `host`ï¼ˆBYO è‡ªå¸¦æœåŠ¡å™¨ï¼‰å’Œ `instance`ï¼ˆäº‘ç«¯ GPUï¼‰ï¼Œå¦åˆ™æŠ¥é”™ã€‚

---

### **4. è¿œç¨‹ç¯å¢ƒå®‰è£…**
```python
example_dir = args.example.rsplit("/", 1)[0]

# Set up remote environment
cluster.install_packages(["pip:./"])  # Installs transformers from local source
cluster.run([f"pip install -r transformers/examples/{example_dir}/requirements.txt"])
cluster.run(["pip install torch --upgrade --extra-index-url https://download.pytorch.org/whl/cu117"])
```
- **è®¾ç½® `example_dir`**
  ```python
  example_dir = args.example.rsplit("/", 1)[0]
  ```
  è§£æ `pytorch/text-generation/run_generation.py` çš„ç›®å½•è·¯å¾„ `pytorch/text-generation`ã€‚

- **å®‰è£… Hugging Face ä¾èµ–**
  ```python
  cluster.install_packages(["pip:./"])
  ```
  å®‰è£… **æœ¬åœ° transformers åº“**ï¼ˆå¦‚æœåœ¨æœ¬åœ°å¼€å‘äº†æ–°çš„ `transformers` ç‰ˆæœ¬ï¼Œå¯ä»¥æ¨é€åˆ°è¿œç¨‹ï¼‰ã€‚

- **å®‰è£…ç¤ºä¾‹è„šæœ¬çš„ Python ä¾èµ–**
  ```python
  cluster.run([f"pip install -r transformers/examples/{example_dir}/requirements.txt"])
  ```
  è¯»å– `requirements.txt` å¹¶å®‰è£…æ‰€æœ‰éœ€è¦çš„åŒ…ï¼ˆå¦‚ `datasets`, `torch`, `transformers` ç­‰ï¼‰ã€‚

- **å‡çº§ PyTorch**
  ```python
  cluster.run(["pip install torch --upgrade --extra-index-url https://download.pytorch.org/whl/cu117"])
  ```
  - `cu117` è¡¨ç¤º **CUDA 11.7** ç‰ˆæœ¬çš„ PyTorchï¼Œé€‚ç”¨äº GPU è®¡ç®—ã€‚

---

### **5. è¿œç¨‹æ‰§è¡Œ Hugging Face è®­ç»ƒè„šæœ¬**
```python
cluster.run([f'python transformers/examples/{args.example} {" ".join(shlex.quote(arg) for arg in unknown)}'])
```
- **æ ¸å¿ƒé€»è¾‘**ï¼š
  - è¿è¡Œ Hugging Face å®˜æ–¹çš„ `run_generation.py` **è®­ç»ƒ/æ¨ç†** è„šæœ¬ã€‚
  - ä¼ é€’å‘½ä»¤è¡Œå‚æ•° `unknown`ï¼Œå¦‚ï¼š
    ```shell
    python transformers/examples/pytorch/text-generation/run_generation.py --batch_size 32
    ```

---

### **6. å¦ä¸€ç§æ–¹æ³•ï¼šç›´æ¥è¿è¡Œ Python è®­ç»ƒå‡½æ•°**
```python
# Alternatively, we can just import and run a training function (especially if there's no wrapper CLI):
# from my_script... import train
# reqs = ['pip:./', 'torch', 'datasets', 'accelerate', 'evaluate', 'tqdm', 'scipy', 'scikit-learn', 'tensorboard']
# launch_train_gpu = rh.function(fn=train,
#                                system=gpu,
#                                reqs=reqs,
#                                name='train_bert_glue')
#
# launch_train_gpu(num_epochs = 3, lr = 2e-5, seed = 42, batch_size = 16, stream_logs=True)
```
- è¿™æ®µæ³¨é‡Šä»£ç æä¾›äº†ä¸€ç§ **æ›´é«˜çº§çš„æ–¹å¼** è¿è¡Œè®­ç»ƒï¼š
  - ç›´æ¥ **è°ƒç”¨ Python è®­ç»ƒå‡½æ•°**ï¼Œè€Œä¸æ˜¯è¿è¡Œå‘½ä»¤è¡Œè„šæœ¬ã€‚
  - `launch_train_gpu` ç»‘å®šäº† `train` è®­ç»ƒå‡½æ•°åˆ° GPU æœåŠ¡å™¨ä¸Šã€‚
  - ç›´æ¥ä¼ é€’ `num_epochs=3, lr=2e-5` è¿™äº›è®­ç»ƒå‚æ•°ã€‚

---

## **æ€»ç»“**
### **1. ä»£ç ä¸»è¦åŠŸèƒ½**
âœ… **è¿œç¨‹æ‰§è¡Œ Hugging Face è®­ç»ƒè„šæœ¬**  
âœ… **æ”¯æŒæœ¬åœ°æœåŠ¡å™¨ï¼ˆBYOï¼‰å’Œäº‘ç«¯ GPUï¼ˆRunhouseï¼‰**  
âœ… **è‡ªåŠ¨å®‰è£…ä¾èµ–ï¼ˆ`pip install -r requirements.txt`ï¼‰**  
âœ… **æ”¯æŒ NCCL/GPU è®­ç»ƒ**

### **2. é€‚ç”¨äº**
- **Hugging Face å®˜æ–¹ç¤ºä¾‹è®­ç»ƒ**
- **åˆ†å¸ƒå¼è®­ç»ƒï¼ˆNCCLï¼‰**
- **å¤šæœºå¤šå¡è®­ç»ƒ**
- **æœ¬åœ°å¼€å‘ + è¿œç¨‹äº‘ GPU è®­ç»ƒï¼ˆV100/A100ï¼‰**

### **3. æ”¹è¿›å»ºè®®**
1. **æ”¯æŒæ›´å¤š GPUï¼ˆA100, H100ï¼‰**
   ```python
   parser.add_argument("--instance", type=str, default="A100:1")
   ```
2. **ä¼˜åŒ– NCCL å¤šå¡è®­ç»ƒ**
   - æ”¹è¿› `run_generation.py` æ”¯æŒ `torch.distributed.launch`ã€‚

3. **æ”¯æŒ `accelerate`ï¼ˆæ›´é«˜æ•ˆçš„åˆ†å¸ƒå¼è®­ç»ƒï¼‰**
   ```shell
   accelerate launch transformers/examples/pytorch/text-generation/run_generation.py
   ```

---

## **ä½ çš„éœ€æ±‚**
- ä½ æ˜¯æƒ³ **æœ¬åœ°è°ƒè¯•** è¿˜æ˜¯ **è¿œç¨‹äº‘ GPU è®­ç»ƒ**ï¼Ÿ
- ä½ ç”¨çš„ **ä»€ä¹ˆ Hugging Face ä»»åŠ¡ï¼ˆGPTã€BERTã€Llamaï¼‰**ï¼Ÿ
- ä½ å¸Œæœ›æ”¹è¿› **è®­ç»ƒé€Ÿåº¦** è¿˜æ˜¯ **åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ**ï¼Ÿ

å¦‚æœä½ æœ‰å…·ä½“çš„è®­ç»ƒéœ€æ±‚ï¼Œæˆ‘å¯ä»¥å¸®ä½  **ä¼˜åŒ–å¤šå¡è®­ç»ƒç­–ç•¥** ğŸš€