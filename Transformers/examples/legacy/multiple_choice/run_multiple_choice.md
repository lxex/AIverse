è¿™æ®µä»£ç ç”¨äº **å¾®è°ƒï¼ˆFinetuneï¼‰Hugging Face Transformers åº“ä¸­çš„å¤šé¡¹é€‰æ‹©ï¼ˆMultiple Choiceï¼‰æ¨¡å‹**ï¼Œæ”¯æŒ **BERTã€RoBERTaã€XLNet** è¿™ç±»é¢„è®­ç»ƒæ¨¡å‹ã€‚

---

## **ğŸ“Œ 1. ä»£ç ä¸»è¦åŠŸèƒ½**
âœ… **æ”¯æŒå¾®è°ƒå¤šé¡¹é€‰æ‹©ï¼ˆMultiple Choiceï¼‰ä»»åŠ¡ï¼ˆå¦‚ SWAG, ARC, RACEï¼‰**  
âœ… **åŠ è½½ Hugging Face é¢„è®­ç»ƒæ¨¡å‹å¹¶é€‚é…ä»»åŠ¡**  
âœ… **æ”¯æŒ `Trainer` API è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°**  
âœ… **å¯é€‰æ‹© GPU/TPU è¿›è¡ŒåŠ é€Ÿ**  
âœ… **è‡ªåŠ¨è®¡ç®—å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**

---

## **ğŸ“Œ 2. ä»£ç è§£æ**
### **1ï¸âƒ£ è§£æå‘½ä»¤è¡Œå‚æ•°**
```python
parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))
model_args, data_args, training_args = parser.parse_args_into_dataclasses()
```
- **`ModelArguments`**ï¼šæ¨¡å‹ç›¸å…³å‚æ•°ï¼ˆæ¨¡å‹åç§°ã€ç¼“å­˜ç›®å½•ç­‰ï¼‰
- **`DataTrainingArguments`**ï¼šæ•°æ®ç›¸å…³å‚æ•°ï¼ˆæ•°æ®ç›®å½•ã€æœ€å¤§åºåˆ—é•¿åº¦ç­‰ï¼‰
- **`TrainingArguments`**ï¼šè®­ç»ƒç›¸å…³å‚æ•°ï¼ˆæ‰¹æ¬¡å¤§å°ã€å­¦ä¹ ç‡ã€è®­ç»ƒæ­¥æ•°ç­‰ï¼‰

âœ… **ç¤ºä¾‹**
```bash
python run_multiple_choice.py \
    --model_name_or_path bert-base-uncased \
    --task_name swag \
    --data_dir ./data \
    --output_dir ./output \
    --do_train \
    --do_eval
```

---

### **2ï¸âƒ£ è®¾å®šæ—¥å¿—**
```python
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    datefmt="%m/%d/%Y %H:%M:%S",
    level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,
)
```
- **`local_rank in [-1, 0]`**ï¼šåªåœ¨ **ä¸»è¿›ç¨‹** è®°å½•æ—¥å¿—ï¼ˆé¿å…å¤š GPU å¹¶è¡Œè®­ç»ƒæ—¶é‡å¤æ‰“å°ï¼‰

---

### **3ï¸âƒ£ åŠ è½½æ•°æ®é›†**
```python
processor = processors[data_args.task_name]()
label_list = processor.get_labels()
num_labels = len(label_list)
```
- **ä» `processors` åŠ è½½æŒ‡å®šä»»åŠ¡çš„å¤„ç†å™¨**
- **è·å–æ‰€æœ‰ç±»åˆ«çš„æ ‡ç­¾**
- **è®¡ç®— `num_labels` ç”¨äºé…ç½®æ¨¡å‹**

---
### **4ï¸âƒ£ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹**
```python
config = AutoConfig.from_pretrained(
    model_args.config_name if model_args.config_name else model_args.model_name_or_path,
    num_labels=num_labels,
    finetuning_task=data_args.task_name,
)
tokenizer = AutoTokenizer.from_pretrained(
    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,
)
model = AutoModelForMultipleChoice.from_pretrained(
    model_args.model_name_or_path,
    config=config,
)
```
- **`AutoConfig`**ï¼šåŠ è½½æ¨¡å‹é…ç½®ï¼ˆè‡ªåŠ¨åŒ¹é… `num_labels`ï¼‰
- **`AutoTokenizer`**ï¼šåŠ è½½åˆ†è¯å™¨ï¼ˆè‡ªåŠ¨åŒ¹é… `BERT / RoBERTa / XLNet`ï¼‰
- **`AutoModelForMultipleChoice`**ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹

âœ… **æ”¯æŒçš„æ¨¡å‹**
- `bert-base-uncased`
- `roberta-base`
- `xlnet-base-cased`
- `albert-base-v2`
- `deberta-v3-base`
- `gpt2`ï¼ˆéƒ¨åˆ†å¤šé€‰ä»»åŠ¡é€‚é…ï¼‰

---

### **5ï¸âƒ£ è®­ç»ƒé›† & éªŒè¯é›†**
```python
train_dataset = (
    MultipleChoiceDataset(
        data_dir=data_args.data_dir,
        tokenizer=tokenizer,
        task=data_args.task_name,
        max_seq_length=data_args.max_seq_length,
        overwrite_cache=data_args.overwrite_cache,
        mode=Split.train,
    )
    if training_args.do_train
    else None
)
eval_dataset = (
    MultipleChoiceDataset(
        data_dir=data_args.data_dir,
        tokenizer=tokenizer,
        task=data_args.task_name,
        max_seq_length=data_args.max_seq_length,
        overwrite_cache=data_args.overwrite_cache,
        mode=Split.dev,
    )
    if training_args.do_eval
    else None
)
```
ğŸ”¹ **`MultipleChoiceDataset`**ï¼šå¯¹ **è¾“å…¥æ–‡æœ¬å¯¹ï¼ˆquestion, choiceï¼‰è¿›è¡Œ Tokenization å¤„ç†**
ğŸ”¹ **`mode=Split.train/dev`**ï¼šæ”¯æŒ **è®­ç»ƒé›†ï¼ˆtrainï¼‰å’ŒéªŒè¯é›†ï¼ˆdevï¼‰**

âœ… **ç¤ºä¾‹**
- **SWAG ä»»åŠ¡ï¼ˆå¥å­é¢„æµ‹ï¼‰**
  ```python
  context = "She went to the kitchen."
  choices = ["She grabbed an apple.", "He played basketball."]
  ```
  - ç›®æ ‡æ˜¯ä» `choices` ä¸­ **é€‰æ‹©æœ€åˆç†çš„å¥å­**
---

### **6ï¸âƒ£ è®¡ç®—å‡†ç¡®ç‡**
```python
def compute_metrics(p: EvalPrediction) -> Dict:
    preds = np.argmax(p.predictions, axis=1)
    return {"acc": simple_accuracy(preds, p.label_ids)}
```
- **`p.predictions`**ï¼šæ¨¡å‹è¾“å‡ºçš„ `logits`
- **`np.argmax(..., axis=1)`**ï¼šé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„é€‰é¡¹
- **`simple_accuracy`**ï¼šè®¡ç®—å‡†ç¡®ç‡

---

### **7ï¸âƒ£ è®­ç»ƒ & è¯„ä¼°**
```python
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    compute_metrics=compute_metrics,
    data_collator=data_collator,
)

if training_args.do_train:
    trainer.train()
    trainer.save_model()
```
- **`Trainer`** ç»Ÿä¸€ç®¡ç†è®­ç»ƒæµç¨‹ï¼ˆæ”¯æŒ GPU/TPUï¼‰
- **`trainer.train()`** è¿›è¡Œæ¨¡å‹è®­ç»ƒ
- **`trainer.save_model()`** ä¿å­˜æ¨¡å‹

âœ… **ç¤ºä¾‹**
```bash
python run_multiple_choice.py --do_train --do_eval
```

---

## **ğŸ“Œ 3. è®­ç»ƒå‘½ä»¤**
**âœ… SWAG ä»»åŠ¡**
```bash
python run_multiple_choice.py \
    --model_name_or_path bert-base-uncased \
    --task_name swag \
    --data_dir ./data \
    --output_dir ./output \
    --do_train \
    --do_eval \
    --max_seq_length 128 \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 8 \
    --learning_rate 2e-5 \
    --num_train_epochs 3
```

---

## **ğŸ“Œ 4. ä»£ç æ€»ç»“**
âœ… **é€‚ç”¨äºå¤šé¡¹é€‰æ‹©ä»»åŠ¡ï¼ˆMultiple Choiceï¼‰**  
âœ… **æ”¯æŒ `BERT`ã€`RoBERTa`ã€`XLNet` é¢„è®­ç»ƒæ¨¡å‹**  
âœ… **è‡ªåŠ¨ Tokenize ä»»åŠ¡æ•°æ®ï¼Œæ”¯æŒ `Trainer` è®­ç»ƒ**  
âœ… **è‡ªåŠ¨è®¡ç®—å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**  
âœ… **å¯ç”¨äºå¤šä¸ª NLP ä»»åŠ¡ï¼ˆå¦‚ SWAG, RACE, ARCï¼‰**

ğŸš€ **å¯ä»¥å°è¯•ä¸åŒçš„ `batch_size / learning_rate` æ‰¾åˆ°æœ€ä½³è¶…å‚æ•°ï¼**